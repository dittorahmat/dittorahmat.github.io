<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data With Ditto</title>
    <link>https://example.org/</link>
    <description>Recent content on Data With Ditto</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Optimizing SQLite Databases: A Junior Developer&#39;s Guide</title>
      <link>https://example.org/sqlite-optimization-guide/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://example.org/sqlite-optimization-guide/</guid>
      <description>&lt;h1 id=&#34;optimizing-sqlite-databases-a-junior-developers-guide&#34;&gt;Optimizing SQLite Databases: A Junior Developer&amp;rsquo;s Guide&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Today, I&amp;rsquo;m going to walk you through some cool ways to keep your SQLite database running smoothly. If you&amp;rsquo;ve ever wondered how to clean up and speed up your database, you&amp;rsquo;re in the right place.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-performance-problem&#34;&gt;The Performance Problem&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s face it - databases can get messy. Over time, they accumulate deleted data, fragmentation, and performance bottlenecks. That&amp;rsquo;s where database optimization comes in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Solving PostgreSQL Connection Nightmares: A Real-World Troubleshooting Guide</title>
      <link>https://example.org/postgresql-connection-management-troubleshooting-guide/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://example.org/postgresql-connection-management-troubleshooting-guide/</guid>
      <description>&lt;h1 id=&#34;the-connection-count-conundrum&#34;&gt;The Connection Count Conundrum&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Ever dealt with a database that&amp;rsquo;s throwing a tantrum with endless connection creep? This is a story of how we wrestled our PostgreSQL connections back into submission.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-initial-cry-for-help&#34;&gt;The Initial Cry for Help&lt;/h2&gt;&#xA;&lt;p&gt;Our team was facing a gnarly problem: PostgreSQL connections were multiplying like rabbits, and our application performance was taking a serious hit. We needed a hero (or in this case, a systematic approach) to save the day.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Taming Large TSV Files: My Journey to Efficient MySQL Imports</title>
      <link>https://example.org/import-large-tsv-file-to-mysql/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://example.org/import-large-tsv-file-to-mysql/</guid>
      <description>&lt;h1 id=&#34;taming-large-tsv-files-my-journey-to-efficient-mysql-imports&#34;&gt;Taming Large TSV Files: My Journey to Efficient MySQL Imports&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Today, I&amp;rsquo;m going to walk you through solving a tricky database import problem I recently helped someone solve. If you&amp;rsquo;ve ever struggled with importing massive TSV files into MySQL, this guide is for you.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-initial-challenge&#34;&gt;The Initial Challenge&lt;/h2&gt;&#xA;&lt;p&gt;My colleague came to me with a pretty common big data problem:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They needed to import a massive TSV file (2.25 GB, around 15 million rows)&lt;/li&gt;&#xA;&lt;li&gt;MySQL Workbench&amp;rsquo;s import wizard was failing miserably&lt;/li&gt;&#xA;&lt;li&gt;They wanted a reliable way to:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Import large files&lt;/li&gt;&#xA;&lt;li&gt;Update existing tables&lt;/li&gt;&#xA;&lt;li&gt;Manage the data efficiently&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;the-solution-a-custom-python-import-script&#34;&gt;The Solution: A Custom Python Import Script&lt;/h2&gt;&#xA;&lt;p&gt;After some brainstorming, I developed a Python script that tackles these challenges head-on. Here&amp;rsquo;s why it&amp;rsquo;s awesome:&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Ditto</title>
      <link>https://example.org/about/</link>
      <pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://example.org/about/</guid>
      <description>&lt;p&gt;Hey there! I&amp;rsquo;m Ditto, a Senior Data Engineer and Business Intelligence pro with over 17 years of experience in the data world. I&amp;rsquo;ve spent my career building data warehouses, developing ETL pipelines, and creating business intelligence solutions that help companies make better decisions.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve worked with a variety of companies, from startups to large enterprises, and I&amp;rsquo;ve always been passionate about using data to solve problems and drive business value.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
