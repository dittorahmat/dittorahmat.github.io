<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data With Ditto</title>
    <link>https://dittorahmat.github.io/</link>
    <description>Recent content on Data With Ditto</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://dittorahmat.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building an SQL System for API Data and Automated Reporting</title>
      <link>https://dittorahmat.github.io/sql-api-integration-pipeline/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/sql-api-integration-pipeline/</guid>
      <description>&lt;h2 id=&#34;the-challenge&#34;&gt;The Challenge&lt;/h2&gt;&#xA;&lt;p&gt;Recently, I was looking into building a system that could:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Pull data from external APIs using SQL&lt;/li&gt;&#xA;&lt;li&gt;Store this data efficiently&lt;/li&gt;&#xA;&lt;li&gt;Set up automatic alerts based on specific conditions&lt;/li&gt;&#xA;&lt;li&gt;Generate and send custom reports based on these alerts&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s what I learned.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-solution-sql--api-integration-pipeline&#34;&gt;The Solution: SQL + API Integration Pipeline&lt;/h2&gt;&#xA;&lt;p&gt;The solution involves several components working together:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-database-setup&#34;&gt;1. Database Setup&lt;/h3&gt;&#xA;&lt;p&gt;You need a solid database to store your API data. Popular options include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recovering a WordPress Site from a Dead GCP VM</title>
      <link>https://dittorahmat.github.io/recovering-wordpress-hosted-in-gcp-vm/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/recovering-wordpress-hosted-in-gcp-vm/</guid>
      <description>&lt;h1 id=&#34;recovering-a-wordpress-site-from-a-dead-gcp-vm&#34;&gt;Recovering a WordPress Site from a Dead GCP VM&lt;/h1&gt;&#xA;&lt;p&gt;We&amp;rsquo;ve all been there - a production VM suddenly becomes inaccessible, and with it, an entire WordPress site disappears. In this post, I&amp;rsquo;ll walk through a recent recovery process I had to perform when a client&amp;rsquo;s WordPress site went offline due to VM issues on Google Cloud Platform.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;&#xA;&lt;p&gt;My client reached out with this urgent issue:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;I need help to recover and restore a WordPress website hosted on a Google Cloud Platform VM.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimizing SQLite Databases: A Junior Developer&#39;s Guide</title>
      <link>https://dittorahmat.github.io/sqlite-optimization-guide/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/sqlite-optimization-guide/</guid>
      <description>&lt;h1 id=&#34;optimizing-sqlite-databases-a-junior-developers-guide&#34;&gt;Optimizing SQLite Databases: A Junior Developer&amp;rsquo;s Guide&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Today, I&amp;rsquo;m going to walk you through some cool ways to keep your SQLite database running smoothly. If you&amp;rsquo;ve ever wondered how to clean up and speed up your database, you&amp;rsquo;re in the right place.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-performance-problem&#34;&gt;The Performance Problem&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s face it - databases can get messy. Over time, they accumulate deleted data, fragmentation, and performance bottlenecks. That&amp;rsquo;s where database optimization comes in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Solving PostgreSQL Connection Nightmares: A Real-World Troubleshooting Guide</title>
      <link>https://dittorahmat.github.io/postgresql-connection-management-troubleshooting-guide/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/postgresql-connection-management-troubleshooting-guide/</guid>
      <description>&lt;h1 id=&#34;the-connection-count-conundrum&#34;&gt;The Connection Count Conundrum&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Ever dealt with a database that&amp;rsquo;s throwing a tantrum with endless connection creep? This is a story of how we wrestled our PostgreSQL connections back into submission.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-initial-cry-for-help&#34;&gt;The Initial Cry for Help&lt;/h2&gt;&#xA;&lt;p&gt;Our team was facing a gnarly problem: PostgreSQL connections were multiplying like rabbits, and our application performance was taking a serious hit. We needed a hero (or in this case, a systematic approach) to save the day.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Taming Large TSV Files: My Journey to Efficient MySQL Imports</title>
      <link>https://dittorahmat.github.io/import-large-tsv-file-to-mysql/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/import-large-tsv-file-to-mysql/</guid>
      <description>&lt;h1 id=&#34;taming-large-tsv-files-my-journey-to-efficient-mysql-imports&#34;&gt;Taming Large TSV Files: My Journey to Efficient MySQL Imports&lt;/h1&gt;&#xA;&lt;p&gt;Hey there! Today, I&amp;rsquo;m going to walk you through solving a tricky database import problem I recently helped someone solve. If you&amp;rsquo;ve ever struggled with importing massive TSV files into MySQL, this guide is for you.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-initial-challenge&#34;&gt;The Initial Challenge&lt;/h2&gt;&#xA;&lt;p&gt;My colleague came to me with a pretty common big data problem:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They needed to import a massive TSV file (2.25 GB, around 15 million rows)&lt;/li&gt;&#xA;&lt;li&gt;MySQL Workbench&amp;rsquo;s import wizard was failing miserably&lt;/li&gt;&#xA;&lt;li&gt;They wanted a reliable way to:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Import large files&lt;/li&gt;&#xA;&lt;li&gt;Update existing tables&lt;/li&gt;&#xA;&lt;li&gt;Manage the data efficiently&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;the-solution-a-custom-python-import-script&#34;&gt;The Solution: A Custom Python Import Script&lt;/h2&gt;&#xA;&lt;p&gt;After some brainstorming, I developed a Python script that tackles these challenges head-on. Here&amp;rsquo;s why it&amp;rsquo;s awesome:&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Ditto</title>
      <link>https://dittorahmat.github.io/about/</link>
      <pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://dittorahmat.github.io/about/</guid>
      <description>&lt;p&gt;Hey there! I&amp;rsquo;m Ditto, a Senior Data Engineer and Business Intelligence pro with over 17 years of experience in the data world. I&amp;rsquo;ve spent my career building data warehouses, developing ETL pipelines, and creating business intelligence solutions that help companies make better decisions.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve worked with a variety of companies, from startups to large enterprises, and I&amp;rsquo;ve always been passionate about using data to solve problems and drive business value.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
